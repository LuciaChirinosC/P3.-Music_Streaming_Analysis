{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario general del revisor</b> <a class=\"tocSkip\"></a><br />\nStatus del proyecto: <b>Aprobado</b>\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "\u00a1Hola!<br />\nSoy **Francisco Cort\u00e9s**, estoy contento de revisar tu proyecto y ser parte de tu proceso de aprendizaje.\nA lo largo del texto, har\u00e9 algunas observaciones sobre mejoras en el c\u00f3digo y tambi\u00e9n har\u00e9 comentarios sobre tus percepciones sobre el tema. Si existe alg\u00fan error en el c\u00f3digo, no te preocupes, estoy aqu\u00ed para ayudarte a mejorarlo, en la primera iteraci\u00f3n te lo se\u00f1alar\u00e9 para que tengas la oportunidad de corregirlo, pero si a\u00fan no encuentras una soluci\u00f3n para esta tarea, te dar\u00e9 una pista m\u00e1s precisa en la pr\u00f3xima iteraci\u00f3n y tambi\u00e9n algunos ejemplos pr\u00e1cticos. Estar\u00e9 abierto a retroalimentaci\u00f3n y discusiones sobre el tema.<br />\nEncontrar\u00e1s mis comentarios a continuaci\u00f3n - **por favor no los muevas, modifiques o borres**.\nRevisar\u00e9 cuidadosamente tu c\u00f3digo para comprobar que se han cumplido con los requisitos y te proporcionar\u00e9 mis comentarios en cajas verdes, amarillas o rojas como esta:\n\n<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSi la ejecuci\u00f3n fue perfecta succesfully.\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSi existe alguna recomendaci\u00f3n para que tu c\u00f3digo mejore.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nSi existen correcciones necesarias para cumplir con los requisitos. El trabajo no puede ser aceptado si hay alguna caja roja.\n</div>\n\nPuedes responderme de la siguiente manera:\n\n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante.</b> <a class=\"tocSkip\"></a>\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "E0vqbgi9ay0H"}, "source": "# D\u00e9jame escuchar la m\u00fasica"}, {"cell_type": "markdown", "metadata": {"id": "fhq_eyov_Zcs"}, "source": "# Contenido <a id='back'></a>\n\n* [Introducci\u00f3n](#intro)\n* [Etapa 1. Descripci\u00f3n de los datos](#data_review)\n    * [Conclusiones](#data_review_conclusions)\n* [Etapa 2. Preprocesamiento de datos](#data_preprocessing)\n    * [2.1 Estilo del encabezado](#header_style)\n    * [2.2 Valores ausentes](#missing_values)\n    * [2.3 Duplicados](#duplicates)\n    * [2.4 Conclusiones](#data_preprocessing_conclusions)\n* [Etapa 3. Prueba de hip\u00f3tesis](#hypothesis)\n    * [3.1 Hip\u00f3tesis 1: actividad de los usuarios y las usuarias en las dos ciudades](#activity)\n* [Conclusiones](#end)"}, {"cell_type": "markdown", "metadata": {"id": "VUC88oWjTJw2"}, "source": "## Introducci\u00f3n <a id='intro'></a>\nComo analista de datos, tu trabajo consiste en analizar datos para extraer informaci\u00f3n valiosa y tomar decisiones basadas en ellos. Esto implica diferentes etapas, como la descripci\u00f3n general de los datos, el preprocesamiento y la prueba de hip\u00f3tesis.\n\nSiempre que investigamos, necesitamos formular hip\u00f3tesis que despu\u00e9s podamos probar. A veces aceptamos estas hip\u00f3tesis; otras veces, las rechazamos. Para tomar las decisiones correctas, una empresa debe ser capaz de entender si est\u00e1 haciendo las suposiciones correctas.\n\nEn este proyecto, comparar\u00e1s las preferencias musicales de las ciudades de Springfield y Shelbyville. Estudiar\u00e1s datos reales de transmisi\u00f3n de m\u00fasica online para probar la hip\u00f3tesis a continuaci\u00f3n y comparar el comportamiento de los usuarios y las usuarias de estas dos ciudades.\n\n### Objetivo:\nPrueba la hip\u00f3tesis:\n1. La actividad de los usuarios y las usuarias difiere seg\u00fan el d\u00eda de la semana y dependiendo de la ciudad.\n\n\n### Etapas\nLos datos del comportamiento del usuario se almacenan en el archivo `/datasets/music_project_en.csv`. No hay ninguna informaci\u00f3n sobre la calidad de los datos, as\u00ed que necesitar\u00e1s examinarlos antes de probar la hip\u00f3tesis.\n\nPrimero, evaluar\u00e1s la calidad de los datos y ver\u00e1s si los problemas son significativos. Entonces, durante el preprocesamiento de datos, tomar\u00e1s en cuenta los problemas m\u00e1s cr\u00edticos.\n\nTu proyecto consistir\u00e1 en tres etapas:\n 1. Descripci\u00f3n de los datos.\n 2. Preprocesamiento de datos.\n 3. Prueba de hip\u00f3tesis.\n\n\n\n\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "hDt6pg-Rw-1U"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "Ml1hmfXC_Zcs"}, "source": "## Etapa 1. Descripci\u00f3n de los datos <a id='data_review'></a>\n\nAbre los datos y exam\u00ednalos."}, {"cell_type": "markdown", "metadata": {"id": "57eAOGIz_Zcs"}, "source": "Necesitar\u00e1s `pandas`, as\u00ed que imp\u00f3rtalo."}, {"cell_type": "code", "execution_count": 1, "metadata": {"id": "AXN7PHPN_Zcs", "trusted": true}, "outputs": [], "source": "# Importar pandas\nimport pandas as pd\ndf = pd.read_csv(\"/datasets/music_project_en.csv\")\n"}, {"cell_type": "markdown", "metadata": {"id": "SG23P8tt_Zcs"}, "source": "Lee el archivo `music_project_en.csv` de la carpeta `/datasets/` y gu\u00e1rdalo en la variable `df`:"}, {"cell_type": "code", "execution_count": 2, "metadata": {"id": "fFVu7vqh_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65079 entries, 0 to 65078\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0     userID  65079 non-null  object\n 1   Track     63736 non-null  object\n 2   artist    57512 non-null  object\n 3   genre     63881 non-null  object\n 4     City    65079 non-null  object\n 5   time      65079 non-null  object\n 6   Day       65079 non-null  object\ndtypes: object(7)\nmemory usage: 3.5+ MB\nNone\n"}], "source": "# Leer el archivo y almacenarlo en df\n\nprint(df.info())\n"}, {"cell_type": "markdown", "metadata": {"id": "rDoOMd3uTqnZ"}, "source": "Muestra las 10 primeras filas de la tabla:"}, {"cell_type": "code", "execution_count": 3, "metadata": {"id": "oWTVX3gW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     userID                        Track            artist   genre  \\\n0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n1  55204538  Delayed Because of Accident  Andreas R\u00f6nnberg    rock   \n2    20EC38            Funicul\u00ec funicul\u00e0       Mario Lanza     pop   \n3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n4  E2DC1FAE                  Soul People        Space Echo   dance   \n5  842029A1                       Chains          Obladaet  rusrap   \n6  4CB90AA5                         True      Roman Messer   dance   \n7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n8  8FA1D3BE                     L\u2019estate       Julia Dalia  ruspop   \n9  E772D5C0                    Pessimist               NaN   dance   \n\n        City        time        Day  \n0  Shelbyville  20:28:33  Wednesday  \n1  Springfield  14:07:09     Friday  \n2  Shelbyville  20:58:07  Wednesday  \n3  Shelbyville  08:37:09     Monday  \n4  Springfield  08:34:34     Monday  \n5  Shelbyville  13:09:41     Friday  \n6  Springfield  13:00:07  Wednesday  \n7  Springfield  20:47:49  Wednesday  \n8  Springfield  09:17:40     Friday  \n9  Shelbyville  21:20:49  Wednesday  \n"}], "source": "# Obtener las 10 primeras filas de la tabla df\nprint(df.head(10))"}, {"cell_type": "markdown", "metadata": {"id": "EO73Kwic_Zct"}, "source": "Obt\u00e9n la informaci\u00f3n general sobre la tabla con un comando. Conoces el m\u00e9todo que muestra la informaci\u00f3n general que necesitamos."}, {"cell_type": "code", "execution_count": 4, "metadata": {"id": "DSf2kIb-_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65079 entries, 0 to 65078\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0     userID  65079 non-null  object\n 1   Track     63736 non-null  object\n 2   artist    57512 non-null  object\n 3   genre     63881 non-null  object\n 4     City    65079 non-null  object\n 5   time      65079 non-null  object\n 6   Day       65079 non-null  object\ndtypes: object(7)\nmemory usage: 3.5+ MB\nNone\n"}], "source": "# Obtener la informaci\u00f3n general sobre nuestros datos\nprint(df.info())"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\n\nBuena forma de leer los datos y hacer una revisi\u00f3n inicial\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "TaQ2Iwbr_Zct"}, "source": "Estas son nuestras observaciones sobre la tabla. Contiene siete columnas. Almacenan los mismos tipos de datos: `object`.\n\nSeg\u00fan la documentaci\u00f3n:\n- `' userID'`: identificador del usuario o la usuaria;\n- `'Track'`: t\u00edtulo de la canci\u00f3n;\n- `'artist'`: nombre del artista;\n- `'genre'`: g\u00e9nero de la pista;\n- `'City'`: ciudad del usuario o la usuaria;\n- `'time'`: la hora exacta en la que se reprodujo la canci\u00f3n;\n- `'Day'`: d\u00eda de la semana.\n\nPodemos ver tres problemas con el estilo en los encabezados de la tabla:\n1. Algunos encabezados est\u00e1n en may\u00fasculas, otros en min\u00fasculas.\n2. Hay espacios en algunos encabezados.\n3. `Detecta el tercer problema por tu cuenta y descr\u00edbelo aqu\u00ed`.\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "MCB6-dXG_Zct"}, "source": "### Escribe observaciones de tu parte. Estas son algunas de las preguntas que pueden ser \u00fatiles: <a id='data_review_conclusions'></a>\n\n`1.   \u00bfQu\u00e9 tipo de datos tenemos a nuestra disposici\u00f3n en las filas? \u00bfY c\u00f3mo podemos entender lo que almacenan las columnas?`\n\n`2.   \u00bfHay suficientes datos para proporcionar respuestas a nuestra hip\u00f3tesis o necesitamos m\u00e1s informaci\u00f3n?`\n\n`3.   \u00bfNotaste alg\u00fan problema en los datos, como valores ausentes, duplicados o tipos de datos incorrectos?`"}, {"cell_type": "markdown", "metadata": {}, "source": "RESPUESTA:Los datos tienen inconsistencias en los encabezados, con diferencias en may\u00fasculas, min\u00fasculas y \nespacios innecesarios. Adem\u00e1s, hay valores nulos en Track, artist y genre, lo que podr\u00eda afectar el an\u00e1lisis.\nSe tiene que verificar la cantidad de registros duplicados con df.duplicated().sum() y revisar time por el formato que tiene,\npodria afectar mi analisiss.Finalmente antes de procesar los datos, tendre que limpiar los encabezados, \nmanejar los valores nulos y eliminar posibles duplicados."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nBien hecho!<br/>\n\nLas observaciones que haces son buenas\n\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "3eL__vcwViOi"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "SjYF6Ub9_Zct"}, "source": "## Etapa 2. Preprocesamiento de datos <a id='data_preprocessing'></a>\n\nEl objetivo aqu\u00ed es preparar los datos para que sean analizados.\nEl primer paso es resolver cualquier problema con los encabezados. Luego podemos avanzar a los valores ausentes y duplicados. Empecemos.\n\nCorrige el formato en los encabezados de la tabla.\n"}, {"cell_type": "markdown", "metadata": {"id": "dIaKXr29_Zct"}, "source": "### Estilo del encabezado <a id='header_style'></a>\nMuestra los encabezados de la tabla (los nombres de las columnas):"}, {"cell_type": "code", "execution_count": 5, "metadata": {"id": "oKOTdF_Q_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Muestra los nombres de las columnas\n#Primero uso str.strip() para asegurarme que no hayan espacios extra\ndf.columns = df.columns.str.strip()\n#Segundo renombro las columnas donde sea necesario\nnew_columns={'userID':'userid','Track':'track','City':'city','Day':'day'}\ndf=df.rename(columns=new_columns)\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "zj5534cv_Zct"}, "source": "Cambia los encabezados de la tabla de acuerdo con las reglas del buen estilo:\n* Todos los caracteres deben ser min\u00fasculas.\n* Elimina los espacios.\n* Si el nombre tiene varias palabras, utiliza snake_case."}, {"cell_type": "markdown", "metadata": {"id": "Xu0zkfe5zNJe"}, "source": "Anteriormente, aprendiste acerca de la forma autom\u00e1tica de cambiar el nombre de las columnas. Vamos a aplicarla ahora. Utiliza el bucle for para iterar sobre los nombres de las columnas y poner todos los caracteres en min\u00fasculas. Cuando hayas terminado, vuelve a mostrar los encabezados de la tabla:"}, {"cell_type": "code", "execution_count": 6, "metadata": {"id": "6I_RwwMhzM4e", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Bucle en los encabezados poniendo todo en min\u00fasculas\nnew_columns_names=[]\nfor column in df.columns:\n    name_lowered =column.lower()\n    new_columns_names.append(name_lowered)\ndf.columns = new_columns_names\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "pweIRxjSzPYW"}, "source": "Ahora, utilizando el mismo m\u00e9todo, elimina los espacios al principio y al final de los nombres de las columnas e imprime los nombres de las columnas nuevamente:"}, {"cell_type": "code", "execution_count": 7, "metadata": {"id": "vVQXbFyJzSYl", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Bucle en los encabezados eliminando los espacios\nnew_columns_names=[]\nfor column in df.columns:\n    name_no_spaces =column.replace(\" \",\"\")\n    new_columns_names.append(name_no_spaces)\ndf.columns = new_columns_names\nprint(df.columns)\n"}, {"cell_type": "markdown", "metadata": {"id": "yCb8MW1JzURd"}, "source": "Necesitamos aplicar la regla de snake_case a la columna `userid`. Debe ser `user_id`. Cambia el nombre de esta columna y muestra los nombres de todas las columnas cuando hayas terminado."}, {"cell_type": "code", "execution_count": 8, "metadata": {"id": "ISlFqs5y_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Cambiar el nombre de la columna \"userid\"\nnew_columns = {'userid': 'user_id'}\ndf = df.rename(columns=new_columns)\n\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "1dqbh00J_Zct"}, "source": "Comprueba el resultado. Muestra los encabezados una vez m\u00e1s:"}, {"cell_type": "code", "execution_count": 9, "metadata": {"id": "d4NOAmTW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day']\n"}], "source": "# Comprobar el resultado: la lista de encabezados\n\nprint(list(df.columns))"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\nBuena manera de corregir y reemplazar los nombres de las columnas\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "xYJk6ksJVpOl"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "5ISfbcfY_Zct"}, "source": "### Valores ausentes <a id='missing_values'></a>\n Primero, encuentra el n\u00famero de valores ausentes en la tabla. Debes utilizar dos m\u00e9todos en una secuencia para obtener el n\u00famero de valores ausentes."}, {"cell_type": "code", "execution_count": 10, "metadata": {"id": "RskX29qr_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "user_id       0\ntrack      1343\nartist     7567\ngenre      1198\ncity          0\ntime          0\nday           0\ndtype: int64\n"}], "source": "# Calcular el n\u00famero de valores ausentes\nprint(df.isna().sum())\n"}, {"cell_type": "markdown", "metadata": {"id": "qubhgnlO_Zct"}, "source": "No todos los valores ausentes afectan a la investigaci\u00f3n. Por ejemplo, los valores ausentes en `track` y `artist` no son cruciales. Simplemente puedes reemplazarlos con valores predeterminados como el string `'unknown'` (desconocido).\n\nPero los valores ausentes en `'genre'` pueden afectar la comparaci\u00f3n entre las preferencias musicales de Springfield y Shelbyville. En la vida real, ser\u00eda \u00fatil saber las razones por las cuales hay datos ausentes e intentar recuperarlos. Pero no tenemos esa oportunidad en este proyecto. As\u00ed que tendr\u00e1s que:\n* rellenar estos valores ausentes con un valor predeterminado;\n* evaluar cu\u00e1nto podr\u00edan afectar los valores ausentes a tus c\u00f3mputos;"}, {"cell_type": "markdown", "metadata": {"id": "fSv2laPA_Zct"}, "source": "Reemplazar los valores ausentes en las columnas `'track'`, `'artist'` y `'genre'` con el string `'unknown'`. Como mostramos anteriormente en las lecciones, la mejor forma de hacerlo es crear una lista que almacene los nombres de las columnas donde se necesita el reemplazo. Luego, utiliza esta lista e itera sobre las columnas donde se necesita el reemplazo haciendo el propio reemplazo."}, {"cell_type": "code", "execution_count": 11, "metadata": {"id": "KplB5qWs_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "track     0\nartist    0\ngenre     0\ndtype: int64\n"}], "source": "# Bucle en los encabezados reemplazando los valores ausentes con 'unknown'\n\ncolumns_to_fill = ['track', 'artist', 'genre']\nfor column in columns_to_fill:\n    df[column] = df[column].fillna('unknown')\nprint(df[columns_to_fill].isna().sum())\n"}, {"cell_type": "markdown", "metadata": {"id": "Ilsm-MZo_Zct"}, "source": "Ahora comprueba el resultado para asegurarte de que despu\u00e9s del reemplazo no haya valores ausentes en el conjunto de datos. Para hacer esto, cuenta los valores ausentes nuevamente."}, {"cell_type": "code", "execution_count": 12, "metadata": {"id": "Tq4nYRX4_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "user_id    65079\ntrack      65079\nartist     65079\ngenre      65079\ncity       65079\ntime       65079\nday        65079\ndtype: int64\n"}], "source": "# Contar valores ausentes\nprint(df.isna().count())"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\nBuena manera de reemplazar los valores ausentes en el dataframe\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "74ZIBmq9VrsK"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "BWKRtBJ3_Zct"}, "source": "### Duplicados <a id='duplicates'></a>\nEncuentra el n\u00famero de duplicados expl\u00edcitos en la tabla. Una vez m\u00e1s, debes aplicar dos m\u00e9todos en una secuencia para obtener la cantidad de duplicados expl\u00edcitos."}, {"cell_type": "code", "execution_count": 13, "metadata": {"id": "36eES_S0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "3826\n"}], "source": "# Contar duplicados expl\u00edcitos\nprint(df.duplicated().sum())"}, {"cell_type": "markdown", "metadata": {"id": "Ot25h6XR_Zct"}, "source": "Ahora, elimina todos los duplicados. Para ello, llama al m\u00e9todo que hace exactamente esto."}, {"cell_type": "code", "execution_count": 14, "metadata": {"id": "exFHq6tt_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "        user_id                              track            artist  \\\n0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n1      55204538        Delayed Because of Accident  Andreas R\u00f6nnberg   \n2        20EC38                  Funicul\u00ec funicul\u00e0       Mario Lanza   \n3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n4      E2DC1FAE                        Soul People        Space Echo   \n...         ...                                ...               ...   \n65074  729CBB09                            My Name            McLean   \n65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n65076  C5E3A0D5                          Jalopiina           unknown   \n65077  321D0506                      Freight Train     Chas McDevitt   \n65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n\n            genre         city      time        day  \n0            rock  Shelbyville  20:28:33  Wednesday  \n1            rock  Springfield  14:07:09     Friday  \n2             pop  Shelbyville  20:58:07  Wednesday  \n3            folk  Shelbyville  08:37:09     Monday  \n4           dance  Springfield  08:34:34     Monday  \n...           ...          ...       ...        ...  \n65074         rnb  Springfield  13:32:28  Wednesday  \n65075         hip  Shelbyville  10:00:00     Monday  \n65076  industrial  Springfield  20:09:26     Friday  \n65077        rock  Springfield  21:43:59     Friday  \n65078     country  Springfield  21:59:46     Friday  \n\n[61253 rows x 7 columns]\n"}], "source": "# Eliminar duplicados expl\u00edcitos\nprint(df.drop_duplicates())"}, {"cell_type": "markdown", "metadata": {"id": "Im2YwBEG_Zct"}, "source": "Comprobemos ahora si eliminamos con \u00e9xito todos los duplicados. Cuenta los duplicados expl\u00edcitos una vez m\u00e1s para asegurarte de haberlos eliminado todos:"}, {"cell_type": "code", "execution_count": 15, "metadata": {"id": "-8PuNWQ0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0\n"}], "source": "# Comprobar de nuevo si hay duplicados\ndf.drop_duplicates(inplace=True) \nprint(df.duplicated().sum())\n"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nBien hecho!<br/>\nBuena manera de eliminar los duplicados explicitos\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "QlFBsxAr_Zct"}, "source": "Ahora queremos deshacernos de los duplicados impl\u00edcitos en la columna `genre`. Por ejemplo, el nombre de un g\u00e9nero se puede escribir de varias formas. Dichos errores tambi\u00e9n pueden afectar al resultado."}, {"cell_type": "markdown", "metadata": {"id": "eSjWwsOh_Zct"}, "source": "Para hacerlo, primero mostremos una lista de nombres de g\u00e9nero \u00fanicos, ordenados en orden alfab\u00e9tico. Para ello:\n* Extrae la columna `genre` del DataFrame.\n* Llama al m\u00e9todo que devolver\u00e1 todos los valores \u00fanicos en la columna extra\u00edda.\n"}, {"cell_type": "code", "execution_count": 16, "metadata": {"id": "JIUcqzZN_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hip' 'jazz' 'postrock' 'latin'\n 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 't\u00fcrk\u00e7e'\n 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9'\n 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'hip-hop' 'historisch'\n 'downbeat' 'downtempo' 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait'\n 'deutschrock' 'eastern' 'action' 'future' 'electropop' 'folklore'\n 'bollywood' 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras'\n 'afrikaans' 'rhythm' 'sound' 'deutschspr' 'trip' 'lovers' 'choral'\n 'dancepop' 'retro' 'smooth' 'mexican' 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf'\n 'gangsta' 'inspirational' 'idm' 'ethnic' 'bluegrass' 'broadway'\n 'animated' 'americana' 'karadeniz' 'rockabilly' 'colombian' 'self' 'hop'\n 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport' 'ragga' 'traditional'\n 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop' 'glitch' 'documentary'\n 'oceania' 'popeurodance' 'dark' 'vi' 'grunge' 'hardstyle' 'samba'\n 'garage' 'art' 'folktronica' 'entehno' 'mediterranean' 'chamber' 'cuban'\n 'taraftar' 'gypsy' 'hardtechno' 'shoegazing' 'bossa' 'latino' 'worldbeat'\n 'malaysian' 'baile' 'ghazal' 'arabic' 'popelectronic' 'acid' 'kayokyoku'\n 'neoklassik' 'tribal' 'tanzorchester' 'native' 'independent' 'cantautori'\n 'handsup' 'punjabi' 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech'\n 'soulful' 'jam' 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow'\n 'jungle' 'indipop' 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop'\n 'forr\u00f3' 'dirty' 'regional']\n"}], "source": "# Inspeccionar los nombres de g\u00e9neros \u00fanicos\nprint(df[\"genre\"].unique())"}, {"cell_type": "markdown", "metadata": {"id": "qej-Qmuo_Zct"}, "source": "Busca en la lista para encontrar duplicados impl\u00edcitos del g\u00e9nero `hiphop`. Estos pueden ser nombres escritos incorrectamente o nombres alternativos para el mismo g\u00e9nero.\n\nVer\u00e1s los siguientes duplicados impl\u00edcitos:\n* `hip`\n* `hop`\n* `hip-hop`\n\nPara deshacerte de ellos, crea una funci\u00f3n llamada `replace_wrong_genres()` con dos par\u00e1metros:\n* `wrong_genres=`: esta es una lista que contiene todos los valores que necesitas reemplazar.\n* `correct_genre=`: este es un string que vas a utilizar como reemplazo.\n\nComo resultado, la funci\u00f3n deber\u00eda corregir los nombres en la columna `'genre'` de la tabla `df`, es decir, remplazar cada valor de la lista `wrong_genres` por el valor en `correct_genre`.\n\nDentro del cuerpo de la funci\u00f3n, utiliza un bucle `'for'` para iterar sobre la lista de g\u00e9neros incorrectos, extrae la columna `'genre'` y aplica el m\u00e9todo `replace` para hacer correcciones."}, {"cell_type": "code", "execution_count": 17, "metadata": {"id": "ErNDkmns_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n"}], "source": "# Funci\u00f3n para reemplazar duplicados impl\u00edcitos\ndef replace_wrong_genres(wrong_genres, correct_genre):\n    for genre in wrong_genres: \n        df[\"genre\"] = df[\"genre\"].replace(genre, correct_genre) \n\nwrong_genres = [\"hip\", \"hop\", \"hip-hop\"]\n\nreplace_wrong_genres(wrong_genres, \"hiphop\")\n\nprint(df[\"genre\"].unique())"}, {"cell_type": "markdown", "metadata": {"id": "aDoBJxbA_Zct"}, "source": "Ahora, llama a `replace_wrong_genres()` y p\u00e1sale tales argumentos para que retire los duplicados impl\u00edcitos (`hip`, `hop` y `hip-hop`) y los reemplace por `hiphop`:"}, {"cell_type": "code", "execution_count": 18, "metadata": {"id": "YN5i2hpmSo09", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n"}], "source": "# Eliminar duplicados impl\u00edcitos\ndf = df.drop_duplicates()\nprint(df[\"genre\"].unique())  \n "}, {"cell_type": "markdown", "metadata": {"id": "zQKF16_RG15m"}, "source": "Aseg\u00farate de que los nombres duplicados han sido eliminados. Muestra la lista de valores \u00fanicos de la columna `'genre'` una vez m\u00e1s:"}, {"cell_type": "code", "execution_count": 19, "metadata": {"id": "wvixALnFG15m", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n0\n"}], "source": "# Comprobaci\u00f3n de duplicados impl\u00edcitos\ndf = df.drop_duplicates()\nprint(df[\"genre\"].unique()) \nprint(df.duplicated().sum()) "}, {"cell_type": "markdown", "metadata": {"id": "ALgNbvF3VtPA"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "jz6a9-7HQUDd"}, "source": "### Tus observaciones <a id='data_preprocessing_conclusions'></a>\n\n`Describe brevemente lo que has notado al analizar duplicados, c\u00f3mo abordaste sus eliminaciones y qu\u00e9 resultados obtuviste.`"}, {"cell_type": "markdown", "metadata": {"id": "eK1es74rVujj"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": true}, "outputs": [], "source": "RESPUESTA:He aplicado los m\u00e9todos aprendidos durante el Spring 3 para limpiar y organizar los datos. \nConvert\u00ed los nombres de los g\u00e9neros a min\u00fasculas y correg\u00ed duplicados impl\u00edcitos con replace(). \nVerifiqu\u00e9 valores nulos y los complet\u00e9 con \"unknown\" usando fillna(). Luego, detect\u00e9 duplicados con duplicated().sum() \ny los elimin\u00e9 con drop_duplicates(), asegurando una base de datos limpia y lista para el an\u00e1lisis."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto, se eliminaron los duplicados explicitos de manera adecuada y los duplicados implicitos se reemplazaron por un valor estandarizado, los duplicados implicitos por lo general son m\u00e1s dif\u00edciles de encontrar debido a que se requiere contexto/conocimiento de los datos que se estan analizando, bien hecho\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "WttZHXH0SqKk"}, "source": "## Etapa 3. Prueba de hip\u00f3tesis <a id='hypothesis'></a>"}, {"cell_type": "markdown", "metadata": {"id": "Im936VVi_Zcu"}, "source": "### Hip\u00f3tesis: comparar el comportamiento del usuario o la usuaria en las dos ciudades <a id='activity'></a>"}, {"cell_type": "markdown", "metadata": {"id": "nwt_MuaL_Zcu"}, "source": "La hip\u00f3tesis afirma que existen diferencias en la forma en que los usuarios y las usuarias de Springfield y Shelbyville consumen m\u00fasica. Para comprobar esto, usa los datos de tres d\u00edas de la semana: lunes, mi\u00e9rcoles y viernes.\n\n* Agrupa a los usuarios y las usuarias por ciudad.\n* Compara el n\u00famero de canciones que cada grupo reprodujo el lunes, el mi\u00e9rcoles y el viernes.\n"}, {"cell_type": "markdown", "metadata": {"id": "8Dw_YMmT_Zcu"}, "source": "Realiza cada c\u00e1lculo por separado.\n\nEl primer paso es evaluar la actividad del usuario en cada ciudad. Recuerda las etapas dividir-aplicar-combinar de las que hablamos anteriormente en la lecci\u00f3n. Tu objetivo ahora es agrupar los datos por ciudad, aplicar el m\u00e9todo apropiado para contar durante la etapa de aplicaci\u00f3n y luego encontrar la cantidad de canciones reproducidas en cada grupo especificando la columna para obtener el recuento.\n\nA continuaci\u00f3n se muestra un ejemplo de c\u00f3mo deber\u00eda verse el resultado final:\n`df.groupby(by='....')['column'].method()`Realiza cada c\u00e1lculo por separado.\n\nPara evaluar la actividad de los usuarios y las usuarias en cada ciudad, agrupa los datos por ciudad y encuentra la cantidad de canciones reproducidas en cada grupo.\n\n"}, {"cell_type": "code", "execution_count": 21, "metadata": {"id": "0_Qs96oh_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "city\nShelbyville    18512\nSpringfield    42741\nName: track, dtype: int64\n"}], "source": "# Contar las canciones reproducidas en cada ciudad\nprint(df.groupby(by=\"city\")[\"track\"].count())\n"}, {"cell_type": "markdown", "metadata": {"id": "t_Qx-3NewAnK"}, "source": "`Comenta tus observaciones aqu\u00ed`Podemos observar que en Springfield se registraron m\u00e1s del doble de reproducciones que en Shelbyville (42,741 vs. 18,512). Esto indica una mayor actividad musical en Springfield, posiblemente por m\u00e1s usuarios o h\u00e1bitos de consumo distintos."}, {"cell_type": "markdown", "metadata": {"id": "dzli3w8o_Zcu"}, "source": "Ahora agrupemos los datos por d\u00eda de la semana y encontremos el n\u00famero de canciones reproducidas el lunes, mi\u00e9rcoles y viernes. Utiliza el mismo m\u00e9todo que antes, pero ahora necesitamos una agrupaci\u00f3n diferente.\n"}, {"cell_type": "code", "execution_count": 22, "metadata": {"id": "uZMKjiJz_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "day\nFriday       21840\nMonday       21354\nWednesday    18059\nName: track, dtype: int64\n"}], "source": "# Calcular las canciones reproducidas en cada uno de los tres d\u00edas\ndays=[\"Monday\",\"Wednesday\", \"Friday\"]\nprint(df[df[\"day\"].isin(days)].groupby(by=\"day\")[\"track\"].count())"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\nBuena manera de agrupar los datos, buenas observaciones\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "cC2tNrlL_Zcu"}, "source": "`Comenta tus observaciones aqu\u00ed`El n\u00famero de reproducciones son similares los lunes y viernes, con una ligera disminuci\u00f3n los mi\u00e9rcoles. Esto sugiere que la actividad musical es m\u00e1s alta al inicio y final de la semana, posiblemente debido a cambios en la rutina de los usuarios."}, {"cell_type": "markdown", "metadata": {"id": "POzs8bGa_Zcu"}, "source": "Ya sabes c\u00f3mo contar entradas agrup\u00e1ndolas por ciudad o d\u00eda. Ahora necesitas escribir una funci\u00f3n que pueda contar entradas seg\u00fan ambos criterios simult\u00e1neamente.\n\nCrea la funci\u00f3n `number_tracks()` para calcular el n\u00famero de canciones reproducidas en un determinado d\u00eda **y** ciudad. La funci\u00f3n debe aceptar dos par\u00e1metros:\n\n- `day`: un d\u00eda de la semana para filtrar. Por ejemplo, `'Monday'` (lunes).\n- `city`: una ciudad para filtrar. Por ejemplo, `'Springfield'`.\n\nDentro de la funci\u00f3n, aplicar\u00e1s un filtrado consecutivo con indexaci\u00f3n l\u00f3gica.\n\nPrimero filtra los datos por d\u00eda y luego filtra la tabla resultante por ciudad.\n\nDespu\u00e9s de filtrar los datos por dos criterios, cuenta el n\u00famero de valores de la columna 'user_id' en la tabla resultante. Este recuento representa el n\u00famero de entradas que est\u00e1s buscando. Guarda el resultado en una nueva variable y devu\u00e9lvelo desde la funci\u00f3n."}, {"cell_type": "code", "execution_count": 23, "metadata": {"id": "Nz3GdQB1_Zcu", "trusted": true}, "outputs": [], "source": "# Declara la funci\u00f3n number_tracks() con dos par\u00e1metros: day= y city=.\ndef number_tracks(day, city):\n    \n    # Almacena las filas del DataFrame donde el valor en la columna 'day' es igual al par\u00e1metro day=\n    df_day = df[df[\"day\"] == day]\n    \n    # Filtra las filas donde el valor en la columna 'city' es igual al par\u00e1metro city=\n    df_city = df_day[df_day[\"city\"] == city]\n    \n    # Extrae la columna 'user_id' de la tabla filtrada y aplica el m\u00e9todo count()\n    track_count = df_city[\"user_id\"].count()\n      \n    # Devolver el resultado\n    return track_count"}, {"cell_type": "markdown", "metadata": {"id": "ytf7xFrFJQ2r"}, "source": "Llama a `number_tracks()` seis veces, cambiando los valores de los par\u00e1metros para que recuperes los datos de ambas ciudades para cada uno de los tres d\u00edas."}, {"cell_type": "code", "execution_count": 24, "metadata": {"id": "rJcRATNQ_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "15740\n"}], "source": "# El n\u00famero de canciones reproducidas en Springfield el lunes\nprint(number_tracks(\"Monday\", \"Springfield\"))"}, {"cell_type": "code", "execution_count": 25, "metadata": {"id": "hq_ncZ5T_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "5614\n"}], "source": "# El n\u00famero de canciones reproducidas en Shelbyville el lunes\nprint(number_tracks(\"Monday\", \"Shelbyville\"))"}, {"cell_type": "code", "execution_count": 26, "metadata": {"id": "_NTy2VPU_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "11056\n"}], "source": "# El n\u00famero de canciones reproducidas en Springfield el mi\u00e9rcoles\nprint(number_tracks(\"Wednesday\", \"Springfield\"))"}, {"cell_type": "code", "execution_count": 27, "metadata": {"id": "j2y3TAwo_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "7003\n"}], "source": "# El n\u00famero de canciones reproducidas en Shelbyville el mi\u00e9rcoles\nprint(number_tracks(\"Wednesday\", \"Shelbyville\"))"}, {"cell_type": "code", "execution_count": 28, "metadata": {"id": "vYDw5u_K_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "15945\n"}], "source": "# El n\u00famero de canciones reproducidas en Springfield el viernes\nprint(number_tracks(\"Friday\", \"Springfield\"))"}, {"cell_type": "code", "execution_count": 29, "metadata": {"id": "8_yzFtW3_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "5895\n"}], "source": "# El n\u00famero de canciones reproducidas en Shelbyville el viernes\nprint(number_tracks(\"Friday\", \"Shelbyville\"))"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nCorrecto!<br/>\nLa funci\u00f3n que has creado agrupa adecuadamente los datos, bien hecho!\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "-EgPIHYu_Zcu"}, "source": "**Conclusiones**\n\n`Comenta si la hip\u00f3tesis es correcta o se debe rechazar. Explica tu razonamiento.`Veamos que los datos obtenidos de la funci\u00f3n number_tracks(). Si la cantidad de reproducciones var\u00eda significativamente entre Springfield y Shelbyville en los d\u00edas analizados , podemos afirmar que la actividad de los usuarios es diferente seg\u00fan la ciudad y el d\u00eda de la semana.\nEn conslusion\nSi los valores son similares en ambos lugares, la hip\u00f3tesis se rechaza, ya que no habr\u00eda una diferencia clara en el comportamiento de los usuarios seg\u00fan la ubicaci\u00f3n y el d\u00eda."}, {"cell_type": "markdown", "metadata": {"id": "p7nFQajCVw5B"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "ykKQ0N65_Zcv"}, "source": "# Conclusiones <a id='end'></a>"}, {"cell_type": "markdown", "metadata": {"id": "tjUwbHb3_Zcv"}, "source": "`Resume aqu\u00ed tus conclusiones sobre la hip\u00f3tesis.`\nEl an\u00e1lisis muestra que el n\u00famero de reproducciones var\u00eda entre Springfield y Shelbyville, con una mayor actividad en Springfield. Adem\u00e1s, los patrones de reproducci\u00f3n cambian seg\u00fan el d\u00eda de la semana, lo que indica diferencias en el comportamiento de los usuarios. Estos resultados confirman que la actividad musical no es homog\u00e9nea y est\u00e1 influenciada tanto por la ubicaci\u00f3n como por el d\u00eda."}, {"cell_type": "markdown", "metadata": {}, "source": "# Comentario general del revisor\n<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a><br />\nHaces buenas observaciones en tu proyecto, estoy de acuerdo en el punto final que expresas, y me gustar\u00eda agregar otras cosas como que no sabemos como la diferencia en la cantidad de datos, puede ser que una ciudad es m\u00e1s grande que la otra o simplemente hay m\u00e1s usuarios alla, hay m\u00e1s preguntas que respuestas, es un hecho que se necesitan m\u00e1s datos para aceptar una hipotesis como esta. Aunque tambi\u00e9n debemos aceptar que este es un ejercicio simple y que en un ejercicio real puede que tengamos m\u00e1s oportunidades de responder a las preguntas m\u00e1s profundamente.\n\n    \nHas realizado un buen trabajo, me doy cuenta de que has aplicado los conocimientos que has adquirido durante el curso, las conclusiones a las que llegaste son buenas y los procedimientos realizados son correctos, la hipotesis se puede decir que es cierta en este caso limitado de datos, si tuvieramos m\u00e1s datos acerca de las poblaciones tendriamos oportunidad de llegar a conclusiones m\u00e1s certeras.<br/>\n\nContin\u00faa con el buen trabajo y mucho \u00e9xito en el siguiente Sprint!\n</div>\n"}, {"cell_type": "markdown", "metadata": {"id": "azLHu64yOIp7"}, "source": "### Nota\nEn proyectos de investigaci\u00f3n reales, la prueba de hip\u00f3tesis estad\u00edstica es m\u00e1s precisa y cuantitativa. Tambi\u00e9n ten en cuenta que no siempre se pueden sacar conclusiones sobre una ciudad entera a partir de datos de una sola fuente.\n\nAprender\u00e1s m\u00e1s sobre la prueba de hip\u00f3tesis en el sprint de an\u00e1lisis estad\u00edstico de datos."}, {"cell_type": "markdown", "metadata": {"id": "Ju4AHDSgV1FE"}, "source": "[Volver a Contenidos](#back)"}], "metadata": {"ExecuteTimeLog": [{"duration": 159, "start_time": "2025-02-11T14:42:12.378Z"}, {"duration": 159, "start_time": "2025-02-11T14:42:55.837Z"}, {"duration": 12, "start_time": "2025-02-11T14:43:32.673Z"}, {"duration": 696, "start_time": "2025-02-11T14:43:41.868Z"}, {"duration": 58, "start_time": "2025-02-11T14:45:00.172Z"}, {"duration": 58, "start_time": "2025-02-11T14:45:49.876Z"}, {"duration": 116, "start_time": "2025-02-11T14:46:16.980Z"}, {"duration": 98, "start_time": "2025-02-11T14:46:21.595Z"}, {"duration": 21, "start_time": "2025-02-11T14:46:32.420Z"}, {"duration": 21, "start_time": "2025-02-11T14:47:52.943Z"}, {"duration": 7, "start_time": "2025-02-11T14:48:13.103Z"}, {"duration": 23, "start_time": "2025-02-11T14:51:17.039Z"}, {"duration": 6, "start_time": "2025-02-11T15:25:53.248Z"}, {"duration": 8, "start_time": "2025-02-11T15:35:29.689Z"}, {"duration": 17, "start_time": "2025-02-11T15:37:27.537Z"}, {"duration": 13, "start_time": "2025-02-11T15:38:06.183Z"}, {"duration": 9, "start_time": "2025-02-11T15:38:19.042Z"}, {"duration": 7, "start_time": "2025-02-11T15:40:26.701Z"}, {"duration": 8, "start_time": "2025-02-11T15:42:08.458Z"}, {"duration": 7, "start_time": "2025-02-11T15:42:21.366Z"}, {"duration": 6, "start_time": "2025-02-11T15:43:15.959Z"}, {"duration": 6, "start_time": "2025-02-11T15:45:47.246Z"}, {"duration": 3, "start_time": "2025-02-11T15:53:05.351Z"}, {"duration": 3, "start_time": "2025-02-11T15:53:54.520Z"}, {"duration": 4, "start_time": "2025-02-11T15:54:56.441Z"}, {"duration": 3, "start_time": "2025-02-11T15:56:11.622Z"}, {"duration": 6, "start_time": "2025-02-11T15:57:29.723Z"}, {"duration": 6, "start_time": "2025-02-11T15:57:40.638Z"}, {"duration": 7, "start_time": "2025-02-11T15:58:56.012Z"}, {"duration": 6, "start_time": "2025-02-11T16:00:58.754Z"}, {"duration": 7, "start_time": "2025-02-11T16:01:06.442Z"}, {"duration": 13, "start_time": "2025-02-11T16:02:27.560Z"}, {"duration": 7, "start_time": "2025-02-11T16:02:44.418Z"}, {"duration": 7, "start_time": "2025-02-11T16:02:56.978Z"}, {"duration": 6, "start_time": "2025-02-11T16:03:59.780Z"}, {"duration": 702, "start_time": "2025-02-11T16:04:30.528Z"}, {"duration": 231, "start_time": "2025-02-11T16:04:37.092Z"}, {"duration": 8, "start_time": "2025-02-11T16:04:44.125Z"}, {"duration": 28, "start_time": "2025-02-11T16:04:56.563Z"}, {"duration": 26, "start_time": "2025-02-11T16:05:02.013Z"}, {"duration": 2, "start_time": "2025-02-11T16:05:40.128Z"}, {"duration": 13, "start_time": "2025-02-11T16:06:03.643Z"}, {"duration": 20, "start_time": "2025-02-11T16:06:10.697Z"}, {"duration": 14, "start_time": "2025-02-11T16:06:41.649Z"}, {"duration": 167, "start_time": "2025-02-11T16:07:18.844Z"}, {"duration": 366, "start_time": "2025-02-11T16:08:15.443Z"}, {"duration": 21, "start_time": "2025-02-11T16:08:17.549Z"}, {"duration": 6, "start_time": "2025-02-11T16:08:24.163Z"}, {"duration": 20, "start_time": "2025-02-11T16:08:29.183Z"}, {"duration": 10, "start_time": "2025-02-11T16:08:37.901Z"}, {"duration": 5, "start_time": "2025-02-11T16:08:45.212Z"}, {"duration": 3, "start_time": "2025-02-11T16:08:49.700Z"}, {"duration": 11, "start_time": "2025-02-11T16:09:37.627Z"}, {"duration": 8, "start_time": "2025-02-11T16:10:22.925Z"}, {"duration": 4, "start_time": "2025-02-11T16:10:54.956Z"}, {"duration": 6, "start_time": "2025-02-11T16:11:05.727Z"}, {"duration": 7, "start_time": "2025-02-11T16:11:16.158Z"}, {"duration": 3, "start_time": "2025-02-11T16:11:18.002Z"}, {"duration": 17, "start_time": "2025-02-11T16:12:50.398Z"}, {"duration": 4, "start_time": "2025-02-11T16:19:18.498Z"}, {"duration": 20, "start_time": "2025-02-11T16:19:31.142Z"}, {"duration": 18, "start_time": "2025-02-11T16:22:29.268Z"}, {"duration": 41, "start_time": "2025-02-11T16:29:54.363Z"}, {"duration": 46, "start_time": "2025-02-11T16:30:50.972Z"}, {"duration": 42, "start_time": "2025-02-11T16:31:28.689Z"}, {"duration": 81, "start_time": "2025-02-11T16:33:36.975Z"}, {"duration": 3, "start_time": "2025-02-11T16:36:42.712Z"}, {"duration": 3, "start_time": "2025-02-11T16:37:12.275Z"}, {"duration": 5, "start_time": "2025-02-11T16:37:21.619Z"}, {"duration": 5, "start_time": "2025-02-11T16:42:14.016Z"}, {"duration": 4, "start_time": "2025-02-11T16:42:25.390Z"}, {"duration": 4, "start_time": "2025-02-11T16:42:44.064Z"}, {"duration": 4, "start_time": "2025-02-11T16:43:03.574Z"}, {"duration": 12, "start_time": "2025-02-11T16:44:03.296Z"}, {"duration": 77, "start_time": "2025-02-11T16:45:58.016Z"}, {"duration": 6, "start_time": "2025-02-11T16:47:25.821Z"}, {"duration": 5, "start_time": "2025-02-11T16:47:44.383Z"}, {"duration": 4, "start_time": "2025-02-11T16:48:10.242Z"}, {"duration": 43, "start_time": "2025-02-11T16:48:21.424Z"}, {"duration": 4, "start_time": "2025-02-11T16:48:38.433Z"}, {"duration": 76, "start_time": "2025-02-11T16:49:01.991Z"}, {"duration": 75, "start_time": "2025-02-11T16:49:34.244Z"}, {"duration": 9, "start_time": "2025-02-11T17:00:13.134Z"}, {"duration": 6, "start_time": "2025-02-11T17:08:29.218Z"}, {"duration": 16, "start_time": "2025-02-11T17:08:55.923Z"}, {"duration": 4, "start_time": "2025-02-11T17:13:14.159Z"}, {"duration": 3, "start_time": "2025-02-11T17:13:20.589Z"}, {"duration": 11, "start_time": "2025-02-11T17:14:34.697Z"}, {"duration": 14, "start_time": "2025-02-11T17:14:46.306Z"}, {"duration": 13, "start_time": "2025-02-11T17:15:06.559Z"}, {"duration": 12, "start_time": "2025-02-11T17:15:35.751Z"}, {"duration": 14, "start_time": "2025-02-11T17:15:37.521Z"}, {"duration": 13, "start_time": "2025-02-11T17:15:39.594Z"}, {"duration": 481, "start_time": "2025-02-12T10:11:15.382Z"}, {"duration": 22, "start_time": "2025-02-12T10:11:16.348Z"}, {"duration": 6, "start_time": "2025-02-12T10:11:17.504Z"}, {"duration": 23, "start_time": "2025-02-12T10:11:18.256Z"}, {"duration": 10, "start_time": "2025-02-12T10:11:43.977Z"}, {"duration": 4, "start_time": "2025-02-12T10:11:52.500Z"}, {"duration": 4, "start_time": "2025-02-12T10:11:53.413Z"}, {"duration": 10, "start_time": "2025-02-12T10:11:54.773Z"}, {"duration": 2, "start_time": "2025-02-12T10:11:55.582Z"}, {"duration": 17, "start_time": "2025-02-12T10:12:03.372Z"}, {"duration": 20, "start_time": "2025-02-12T10:12:03.936Z"}, {"duration": 16, "start_time": "2025-02-12T10:12:05.610Z"}, {"duration": 46, "start_time": "2025-02-12T10:12:25.177Z"}, {"duration": 47, "start_time": "2025-02-12T10:12:25.621Z"}, {"duration": 78, "start_time": "2025-02-12T10:12:26.539Z"}, {"duration": 6, "start_time": "2025-02-12T10:12:36.681Z"}, {"duration": 11, "start_time": "2025-02-12T10:12:37.988Z"}, {"duration": 44, "start_time": "2025-02-12T10:12:43.163Z"}, {"duration": 84, "start_time": "2025-02-12T10:12:45.619Z"}, {"duration": 11, "start_time": "2025-02-12T10:12:55.037Z"}, {"duration": 9, "start_time": "2025-02-12T10:13:14.351Z"}, {"duration": 15, "start_time": "2025-02-12T10:13:15.870Z"}, {"duration": 3, "start_time": "2025-02-12T10:13:27.045Z"}, {"duration": 14, "start_time": "2025-02-12T10:13:27.944Z"}, {"duration": 11, "start_time": "2025-02-12T10:13:28.296Z"}, {"duration": 11, "start_time": "2025-02-12T10:13:28.590Z"}, {"duration": 11, "start_time": "2025-02-12T10:13:29.143Z"}, {"duration": 12, "start_time": "2025-02-12T10:13:29.374Z"}, {"duration": 11, "start_time": "2025-02-12T10:13:30.528Z"}], "colab": {"collapsed_sections": ["E0vqbgi9ay0H", "VUC88oWjTJw2"], "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 1}